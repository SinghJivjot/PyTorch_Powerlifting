{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diffusion as a Markov Chain\n",
    "\n",
    "$$\n",
    "q(\\mathbf{x}_t | \\mathbf{x}_{t-1}) = \\mathcal{N}(\\mathbf{x}_t; \\sqrt{1-\\beta_t}\\mathbf{x}_{t-1}, \\beta_t\\mathbf{I})\n",
    "$$\n",
    "\n",
    "We can compute the diffused version of an image at any arbitrary time step in the Markov Chain directly from the real image in one shot without having to iteratively perform the forward diffusion process for intermediate timesteps\n",
    "\n",
    "$$\n",
    "q(\\mathbf{x}_t | \\mathbf{x}_0) = \\mathcal{N}(\\mathbf{x}_t; \\sqrt{\\bar{\\alpha_t}} \\mathbf{x}_0, (1 - \\bar{\\alpha_t}) \\mathbf{I})\n",
    "$$\n",
    "$\\text{where } \\alpha_t = 1 - \\beta_t \\text{ and } \\bar{\\alpha_t} = \\prod_{i=1}^{t} \\alpha_i$\n",
    "\n",
    "Derivation:\n",
    "\n",
    "\\begin{align*}\n",
    "q(\\mathbf{x}_t | \\mathbf{x}_{t-1}) &= \\mathcal{N}(\\mathbf{x}_t; \\sqrt{1-\\beta_t}\\mathbf{x}_{t-1}, \\beta_t\\mathbf{I}) \\\\\n",
    "x_t &= \\sqrt{1 - \\beta_t}x_{t-1} + \\sqrt{\\beta_t}\\mathcal{N}(0, I)\n",
    "&= \n",
    "\\end{align*}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the Diffusion class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ForwardDiffusion(nn.Module):\n",
    "    def __init__(self, cap_T, beta_1, beta_T, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        beta_tensor = torch.linspace(beta_1, beta_T, cap_T)\n",
    "        alpha_tensor = 1 - beta_tensor\n",
    "        \n",
    "        self.cum_prod_alpha_tensor = torch.cumprod(alpha_tensor, dim=0)\n",
    "\n",
    "    def apply_noise_kernel(self, timestep, image, noise):\n",
    "        destroy_factor = torch.sqrt(self.cum_prod_alpha_tensor[timestep])\n",
    "        noise_factor = torch.sqrt(1 - self.cum_prod_alpha_tensor[timestep])\n",
    "\n",
    "        diffused_img = (destroy_factor * image) + (noise_factor * noise)\n",
    "\n",
    "        return diffused_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check if Information flows correctly thru the Computational Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 1, 28, 28])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_t = torch.randn(60000, 1, 28, 28).to(device)\n",
    "noise = torch.randn_like(img_t).to(device)\n",
    "\n",
    "diffusion = ForwardDiffusion(1000, 1e-4, 2e-2).to(device)\n",
    "noisy_image_t = diffusion.apply_noise_kernel(1, img_t, noise)\n",
    "\n",
    "noisy_image_t.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the complete MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 1, 28, 28])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_path = '/mnt/c/Users/121js/OneDrive/Desktop/TorchImages/mnist/'\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "mnist = datasets.MNIST(root_path, download=False, transform=transform)\n",
    "\n",
    "loader = DataLoader(mnist, batch_size=60000, shuffle=False)\n",
    "images_tensor, labels = next(iter(loader))\n",
    "\n",
    "images_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use PCA to reduce MNIST data to 1D from 784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_transform(images_tensor):\n",
    "    images_np = images_tensor.numpy().reshape(60000, -1)\n",
    "\n",
    "    pca = PCA(n_components=1)\n",
    "    images_1d = pca.fit_transform(images_np).reshape(-1,)\n",
    "\n",
    "    return images_1d\n",
    "\n",
    "def scale_data(data, lower_a, upper_b):\n",
    "    min_val = data.min()\n",
    "    max_val = data.max()\n",
    "\n",
    "    scaled_data = lower_a + ((data - min_val) * (upper_b - lower_a)) / (max_val - min_val)\n",
    "\n",
    "    return scaled_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to visualize at every timestep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_plot(timestep, dist_1d, which_image):\n",
    "    fig = make_subplots(\n",
    "        rows=1, cols=2, column_widths=[0.5, 0.3], horizontal_spacing=0.2,\n",
    "        subplot_titles=(\"MNIST Distribution (converted to 1D using PCA)\", \"Sampled Image\")\n",
    "    )\n",
    "    fig.update_layout(title=f'Snapshot from Forward Diffusion at timestep = {timestep}', width=1100, showlegend=False, template='plotly_dark')\n",
    "\n",
    "    kde_fig = ff.create_distplot([dist_1d], ['mnist'], show_hist=False, show_rug=False)     # plot the distribution in left panel\n",
    "    for trace in kde_fig['data']:\n",
    "        fig.add_trace(trace, row=1, col=1)\n",
    "\n",
    "    fig.update_xaxes(range=[-1, 1], row=1, col=1)    # Keep the boundaries same to have smooth visualizations\n",
    "    fig.update_yaxes(range=[0, 2], row=1, col=1)\n",
    "\n",
    "    fig.add_trace(go.Heatmap(z=which_image, colorscale='gray', showscale=False), row=1, col=2)     # add the image to the right\n",
    "    fig.update_xaxes(zeroline=False, showticklabels=False, row=1, col=2)\n",
    "    fig.update_yaxes(zeroline=False, showticklabels=False, row=1, col=2)\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_T = 200\n",
    "beta_1 = 1e-4\n",
    "beta_T = 2e-2\n",
    "diffusion = ForwardDiffusion(cap_T, beta_1, beta_T).to(device)\n",
    "\n",
    "images_2_gpu = images_tensor.to(device)\n",
    "\n",
    "image_index = 7\n",
    "\n",
    "for timestep in range(0, cap_T+1):\n",
    "    if timestep == 0:       \n",
    "        # No noise added at timestep=0, just inspect starting conditions\n",
    "        \n",
    "        dist_1d = pca_transform(images_2_gpu.cpu())\n",
    "        scaled_dist_1d = scale_data(dist_1d, -1, 1)\n",
    "\n",
    "        sampled_image = images_2_gpu[image_index].squeeze(0)           # This goes as input to the plotly Heatmap, which expects 2 dim, so thats why squeeze the channel(=1) dim\n",
    "\n",
    "        fig = make_plot(0, scaled_dist_1d, sampled_image.cpu())\n",
    "\n",
    "    else:\n",
    "        transition_kernel = torch.randn_like(images_2_gpu).to(device)\n",
    "\n",
    "        noisy_images = diffusion.apply_noise_kernel(timestep-1, images_2_gpu, transition_kernel)       # timestep=1 corresponds to 0th element in the alpha tensor, so reduce 1\n",
    "\n",
    "        dist_1d = pca_transform(noisy_images.cpu())\n",
    "        scaled_dist_1d = scale_data(dist_1d, -1, 1)\n",
    "\n",
    "        sampled_image = noisy_images[image_index].squeeze(0)\n",
    "\n",
    "        fig = make_plot(timestep, scaled_dist_1d, sampled_image.cpu())\n",
    "\n",
    "    fig.write_image(f'forward_exp_images/{timestep}.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile into GIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_gif():\n",
    "    image_folder = 'forward_exp_images'\n",
    "    images = []\n",
    "    \n",
    "    for timestep in range(1, cap_T+1):\n",
    "        filename = f'{timestep}.png'\n",
    "        image_path = os.path.join(image_folder, filename)\n",
    "        img = Image.open(image_path)\n",
    "        images.append(img)\n",
    "\n",
    "    images[0].save('forward_exp.gif', save_all=True, append_images=images[1:], duration=200, loop=0)\n",
    "\n",
    "make_gif()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
